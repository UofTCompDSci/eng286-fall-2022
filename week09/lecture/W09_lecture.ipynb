{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f60a02e",
   "metadata": {},
   "source": [
    "# Week 9: A Pandas Approach to TTRs in the Colonial South Asian Literature dataset\n",
    "\n",
    "\n",
    "Having learned how to work with **metadata** in Pandas over the previous two weeks — we didn't look at any actual *text* of literary works; just at data **about** texts — this week we learn how to record findings about textual data in Pandas: by storing it in dataframes (and how to turn lists into dataframes, and to merge those lists). Our example of textual analysis is a familiar one: TTRs.\n",
    "\n",
    "Then we combine the two approaches. We load the Colonial South Asian Literature (CSAL) dataset (metadata), and then analyze each text represented in the metadata, calculating its overall and standardized TTR. We record these values, then merge them with a dataframe containing the CSAL metadata.\n",
    "\n",
    "Then we use Pandas to sort, process, and visualize our data, asking whether South Asian or foreign writers had notably divergent TTRs for their discussions of South Asia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066824cd",
   "metadata": {},
   "source": [
    "# Loading the CSAL Dataset\n",
    "\n",
    "Let's begin by loading the CSAL dataset and having a look at what kinds of \"metadata\" it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cff37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df = pd.read_csv('csal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0319b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b046d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c6563",
   "metadata": {},
   "source": [
    "Our task today is to investigate whether the South Asian or \"foreign\" writers use a higher TTR in their works. So the most important column for us at this point is `Nationality of Author`. Let's have a closer look at what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e07be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csal_meta_df['Nationality of Author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803300f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df['Nationality of Author'].value_counts().plot(kind=\"pie\", figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de7816",
   "metadata": {},
   "source": [
    "Let's also have a look at `Genre`, which might be interesting to us in a bit as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87674df",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_meta_df['Genre'].value_counts().plot(kind=\"pie\", figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a43b17",
   "metadata": {},
   "source": [
    "# Approaching TTR Task in Pandas\n",
    "\n",
    "Okay, now let's take a step back and re-approach our TTR task with a Pandas mindset. \n",
    "\n",
    "When we took on this task in the first half of the semester, we just wanted to output our analysis to a CSV spreadsheet file and consider our task done.\n",
    "\n",
    "Now that we have been introduced to Pandas, let's instead plan on gathering our results into DataFrames, with the aim of eventually putting new columns into the `csal_meta_df` DataFrame with TTR values for every text: overall types, overall tokens, overall TTR; standardized types, standardized tokens, standardized TTR. Once we have that big DataFrame with those extra columns, we'll be able to do some fancy analysis!\n",
    "\n",
    "We'll start by recycling our code from a few weeks ago to generate the same CSV files... except this time, we'll load those CSVs back into Python as Pandas dataframes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aafa9f",
   "metadata": {},
   "source": [
    "## Generating TTR CSV files... and Loading Them Back as Pandas DataFrames\n",
    "\n",
    "Let's start by using some code directly recycled** from the Week 5 lecture. \n",
    "\n",
    "The code below iterates through all the files in the `csal` folder, which contains all the CSAL texts, and generates CSV files for their standard and overall values. There are 110 files in the CSAL dataset, some of them quite large, so this will take a second!\n",
    "\n",
    "** There are two tiny differences between this code and the code we used in Week 5: I have grabbed the full file name with extension of each text file in the `Text` column, so that it matches what's in the `csal_meta_df` `Text` columns. You'll see why that's important in a second... The other difference is that this code now labels the columns \"Overall Types\" or \"Standardized Types\" (etc) for more precise columns labels that will also come in handy later.\n",
    "\n",
    "### BEFORE RUNNING THE BELOW CELL: It takes a while to run this code, since the CSAL dataset is pretty big, so I have placed the output files of the below cell in your JupyterHubs for demonstration purposes! IF YOU'RE FOLLOWING ALONG IN CLASS, LET'S AVOID CRASHING THE SERVER BY SKIPPING THE BELOW STEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66c818",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = \"csal/\" # We're telling the code to look in the \"csal/\" subfolder, where the CSAL files all live.\n",
    "\n",
    "sample_size = 0\n",
    "\n",
    "file = open(\"ttr-overall.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Overall Types\",\"Overall Tokens\",\"Overall TTR\"\\n') # Column labels are more precise, identifying whether the column records \"Overall\" or \"Standardized\" values\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    \n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    tokens = len(text_words)\n",
    "    \n",
    "    if sample_size == 0 or tokens < sample_size:\n",
    "        sample_size = tokens\n",
    "    \n",
    "    unique_words = []\n",
    "    \n",
    "    for word in text_words:\n",
    "        word = word.lower()\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "            \n",
    "    types = len(unique_words)\n",
    "    \n",
    "    ttr = (types / tokens) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.name}\",{types},{tokens},{ttr}\\n') # path.name used rather than path.stem so that recoreded filenames match CSAL metadata\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"ttr-standardized.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Standardized Types\",\"Standardized Tokens\",\"Standardized TTR\"\\n') # Column labels are more precise, identifying whether the column records \"Overall\" or \"Standardized\" values\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    text_words_standardized = text_words[:sample_size]\n",
    "    tokens_standardized = len(text_words_standardized)\n",
    "\n",
    "    unique_words_standardized = []\n",
    "    \n",
    "    for word in text_words_standardized:\n",
    "        word = word.lower()\n",
    "        if word not in unique_words_standardized:\n",
    "            unique_words_standardized.append(word)\n",
    "            \n",
    "    types_standardized = len(unique_words_standardized)\n",
    "    \n",
    "    ttr_standardized = (types_standardized / tokens_standardized) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.name}\",{types_standardized},{tokens_standardized},{ttr_standardized}\\n') # path.name used rather than path.stem so that recoreded filenames match CSAL metadata\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97239f",
   "metadata": {},
   "source": [
    "Okay, that has left us with our familiar `ttr-overall.csv` and `ttr-standardized.csv` results files. \n",
    "\n",
    "Let's use our old friend `pd.read_csv()` to load each of those newly created CSV files as Pandas DataFrames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ttr_df = pd.read_csv(\"ttr-overall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db37744",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ttr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_ttr_df = pd.read_csv(\"ttr-standardized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994354a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_ttr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45d22a",
   "metadata": {},
   "source": [
    "# Merging DataFrames\n",
    "\n",
    "Okay, let's say that instead of having our overall and standardized TTR values in separate DataFrames, we wanted to **merge** them into a single DataFrame that contains all the relevant data.\n",
    "\n",
    "Well, we can do that quite easily with Pandas's `.merge()` method. We can only merge DataFrames that contain one column in common — otherwise, Pandas won't know exactly how to combine them. But thankfully our DataFrames do have one column in common: `Text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6930d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_ttr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58da1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "standardized_ttr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f435b8",
   "metadata": {},
   "source": [
    "Below is the command we use to `.merge()` our two DataFrames, **\"on\"** the column they have in common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(overall_ttr_df, standardized_ttr_df, on=\"Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d7a22",
   "metadata": {},
   "source": [
    "Now let's go ahead and stick that into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr_df = pd.merge(overall_ttr_df, standardized_ttr_df, on=\"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6f31d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ttr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45ffd2",
   "metadata": {},
   "source": [
    "# Merging the TTR Data with the CSAL Metadata\n",
    "\n",
    "It's worth remembering at this time that the CSAL Metadata (currently stored in `csal_meta_df`) also contains that same `Text` column — and so we can also create a mega-merged DataFrame that contains all the CSAL metadata and all the TTR analysis we've just done. This will allow us to analyze our TTRs by our various metadata categories, including author nationality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_ttr_df = pd.merge(csal_meta_df, ttr_df, on=\"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19229f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_ttr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a644b00",
   "metadata": {},
   "source": [
    "Let's learn a little more about this new mega-DataFrame we're created..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581f219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csal_ttr_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb55107",
   "metadata": {},
   "source": [
    "This is one of those occasions when `include=\"all\"` parameter on the `df.describe()` method gives us more info that we really want. Let's try again without, which will only give us the \"greatest hits\" columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_ttr_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663bf4fb",
   "metadata": {},
   "source": [
    "# Sorting by Column\n",
    "\n",
    "Before we jump into our actual task for this week, let's see how you would sort the full dataset by Standardized TTR, from lowest to highest; then from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_ttr_df.sort_values(by='Standardized TTR', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_ttr_df.sort_values(by='Standardized TTR', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e937972",
   "metadata": {},
   "source": [
    "# Using GroupBy and Mean to Get Our TTR-by-Nationality Data\n",
    "\n",
    "Now that we have this mega-DataFrame — it contains all the CSAL metadata, and all our precious TTR data — we can pursue our original research question: do texts written by authors from the subcontinent have higher or lower TTRs than texts written by authors identified as foreign?\n",
    "\n",
    "**What data do we actually need to see, in what format, to pursue that research question?**\n",
    "\n",
    "Let's start by using our old friend `df.groupby()` and group this DataFrame by the `Nationality of Author` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_by_nationality_df = csal_ttr_df.groupby('Nationality of Author')\n",
    "csal_by_nationality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820c5cb",
   "metadata": {},
   "source": [
    "DataFrames produced by GroupBy can't be visualized in the standard way that normal DataFrames are. We need to call methods on them to see what's inside. Remember what we're looking for: the **mean standardized TTR for each category of author nationality**. If we just call on old reliable `df.describe()`, we can see that this data is already the `csal_by_nationality_df` DataFrame we just produced. Do you see where it is in the below output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0800be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csal_by_nationality_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5aeac",
   "metadata": {},
   "source": [
    "Here's how we grab only the information we want from `csal_by_nationality_df` — subsetting to the `Standardized TTR` column (using a method we've been using for a few weeks now — passing a `['list containing a single string']` into the `dataframe[ ]` structure) and then calling the Pandas `.mean()` function on that column.\n",
    "\n",
    "What we get from this is just a plain old Pandas DataFrame (not a GroupBy object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_by_nationality_df[['Standardized TTR']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(csal_by_nationality_df[['Standardized TTR']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b7e1b",
   "metadata": {},
   "source": [
    "Now let's stick that into a variable... and let's make a plot of the data we've uncovered... and then interpret the results together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ttr_by_nationality_df = csal_by_nationality_df[['Standardized TTR']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d536e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_ttr_by_nationality_df.plot(kind='bar', figsize=(10,5), title='Standardized TTRs Averaged Across Nationality of Author')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d41206",
   "metadata": {},
   "source": [
    "Let's now look at similar plots for TTR data sorted according to different metadata categories, using the same methods employed above. Does this give you any further insight into the results above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413583d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csal_ttr_by_year_df = csal_ttr_df.groupby('Year')\n",
    "mean_ttr_by_year_df = csal_ttr_by_year_df[['Standardized TTR']].mean()\n",
    "mean_ttr_by_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ttr_by_year_df.plot(figsize=(15,5), title='Standardized TTRs Averaged Across Year of Publication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7673e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ttr_by_genre_df = csal_ttr_df.groupby('Genre')[['Standardized TTR']].mean()\n",
    "mean_ttr_by_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ttr_by_genre_df.plot(kind='bar', figsize=(10,5), title='Standardized TTRs Averaged Across Genre of Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8408c2f",
   "metadata": {},
   "source": [
    "Let's use the techniques we learned last time to produce our gender signal-by-year plots to see exactly how many works in each Genre appear for each of the author nationalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b43cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csal_genre_by_nationality_df = csal_ttr_df.groupby(['Genre', 'Nationality of Author']).size().unstack(fill_value=0)\n",
    "csal_genre_by_nationality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed932c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csal_genre_by_nationality_df.plot(kind='bar', figsize=(10,5), title='Standardized TTRs Averaged Across Genre of Text and Nationality of Author')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683e223",
   "metadata": {},
   "source": [
    "Let's close today's class by \n",
    "\n",
    "- imagining how we could improve our approach to our original research question\n",
    "- thinking of what other research questions we could ask of the CSAL dataset — with the TTR data we've added, or perhaps with some other metadata category or textual metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6e4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "901b79e026e03396fd1ffa7133844e9ea80e258ce34c66e1aabb5896bcb18463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
